{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook For NLP (Natural Language Processing).\n",
    "<hr>\n",
    "\n",
    "* This Notebook is used for the process of social listening.\n",
    "* This notebook processes text (unstructured data)\n",
    "* Initially data brought from SentiOne\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NPL Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the parent directory of 'topology/'\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(parent_dir)  # Add 'parent/' to Python's path\n",
    "\n",
    "from config import settings, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config.m365.auth.microsoft_graph as mg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El directorio ya existe: C:/Users/Santi/Documents/atinna/repos/escuchas\\Azul\\salud\\2025-04-01_2025-04-30\\v1.0\n"
     ]
    }
   ],
   "source": [
    "from config import settings, paths\n",
    "from NLP_optimized import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Usando sesi√≥n existente para santiago.munera@atinna.co\n"
     ]
    }
   ],
   "source": [
    "# Autenticaci√≥n\n",
    "token_response = mg.authenticate(client_id= settings.id_client, auth= settings.AUTHORITY, scopes= settings.GRAPH_SCOPES)\n",
    "headers = mg.get_headers(token_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Azul/salud/2025-04-01_2025-04-30/v1.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{settings.dir_cliente}/{settings.dir_escucha}/{settings.dir_periodo}/{settings.dir_version}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_id = mg.get_team_id(headers, settings.dir_cliente) if headers else None\n",
    "sharepoint_site = mg.get_sharepoint_site(headers, team_id)\n",
    "site_id = sharepoint_site[\"id\"]\n",
    "drive_items = mg.get_drive_items(headers, site_id)\n",
    "dev_folder = next((file for file in drive_items if file[\"name\"].lower() == \"desarrollo\"), None)\n",
    "dev_folder_id = dev_folder[\"id\"]\n",
    "dev_files = mg.get_folder_contents(headers, site_id, dev_folder_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(paths.paths['local']['output']['lda']['base'], exist_ok=True)\n",
    "os.makedirs(paths.paths['local']['output']['lda']['models'], exist_ok=True)\n",
    "os.makedirs(paths.paths['local']['output']['lda']['figures'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Intentando crear 'salud'...\n",
      "üìÇ La carpeta 'salud' ya existe.\n",
      "üìÅ Intentando crear '2025-04-01_2025-04-30'...\n",
      "üìÇ La carpeta '2025-04-01_2025-04-30' ya existe.\n",
      "üìÅ Intentando crear 'v1.0'...\n",
      "üìÇ La carpeta 'v1.0' ya existe.\n",
      "üìÅ Intentando crear 'output'...\n",
      "üìÇ La carpeta 'output' ya existe.\n",
      "üìÅ Intentando crear 'lda'...\n",
      "üìÇ La carpeta 'lda' ya existe.\n"
     ]
    }
   ],
   "source": [
    "mg.create_folder(headers, site_id, dev_folder_id, paths.paths['cloud']['output']['lda']['base'], separator=\"/\")\n",
    "id_folder = mg.get_folder_id(headers, site_id, dev_folder_id, paths.paths['cloud']['output']['lda']['base'], separator=\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id_folder = mg.get_folder_id(headers, site_id, dev_folder_id, paths.paths[\\'cloud\\'][\\'data\\'][\\'base\\'], separator=\"/\")\\nfiles = mg.get_folder_contents(headers, site_id, id_folder)\\nprint(\"\\nüìÇ Archivos en la carpeta Desarrollo:\")\\nfor file in files:\\n    print(f\"- {file[\\'name\\']} ({file[\\'id\\']})\")'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"id_folder = mg.get_folder_id(headers, site_id, dev_folder_id, paths.paths['cloud']['data']['base'], separator=\"/\")\n",
    "files = mg.get_folder_contents(headers, site_id, id_folder)\n",
    "print(\"\\nüìÇ Archivos en la carpeta Desarrollo:\")\n",
    "for file in files:\n",
    "    print(f\"- {file['name']} ({file['id']})\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: C:/Users/Santi/Documents/atinna/repos/escuchas\\Azul\\salud\\2025-04-01_2025-04-30\\v1.0\\data. Downloading...\n",
      "Download complete: C:/Users/Santi/Documents/atinna/repos/escuchas\\Azul\\salud\\2025-04-01_2025-04-30\\v1.0\\data\n"
     ]
    }
   ],
   "source": [
    "file_name = \"espectro_politico-2025-04-01_2025-04-30.csv\"\n",
    "#file_metadata = next((file for file in files if file[\"name\"] == file_name), None)\n",
    "#file_id = file_metadata[\"id\"]\n",
    "local_path = paths.paths['local']['data']['base']\n",
    "file_path = os.path.join(local_path, file_name)\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"File not found: {local_path}. Downloading...\")\n",
    "    #file_metadata = next((file for file in files if file[\"name\"] == file_name), None)\n",
    "    #file_id = file_metadata[\"id\"]\n",
    "\n",
    "    #file = mg.download_file(headers, site_id, file_id, local_path, create_missing_dirs=True)\n",
    "    print(f\"Download complete: {local_path}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"File already exists: {local_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib='polars'#polars, pandas\n",
    "optimization=True\n",
    "\n",
    "#column names and column for use.\n",
    "names = {\n",
    "'Autor':'author',\n",
    "'Contenido de la publicaci√≥n':'content',#Minimum required\n",
    "'Creado':'date',\n",
    "'Contexto':'context',\n",
    "'Link para la fuente':'link',\n",
    "'Grupo de dominio':'domain_group',#Minimum required\n",
    "'Pa√≠s':'country',\n",
    "'Tipo espec√≠fico':'type'\n",
    "}\n",
    "\n",
    "# Filter of values for columns\n",
    "filter_list = ['Twitter','Facebook','Instagram','Video','TikTok','Reddit']\n",
    "\n",
    "new_stop = [\n",
    "    'solo', 'ahora', 'usted', 'bueno', 'si', 'siempre', 'hoy', 'd√≠a', 'dias', 'favor', 'ver', 'verdad', \n",
    "    'verdadero', 'verdadera', 'as√≠', 'decir', 'pasar', 'deber', 'ser', 'nuevo', 'nueva', 'nuevos', \n",
    "    'nuevas', 'hacer', 'pa√≠', 'ud', 'poder', 'querer', 'ir', 'dar', 'saber', 'venir', 'tener', 'creer', \n",
    "    'tanto', 'bien', 'claro', 'seg√∫n', 'sino', 'mismo', 'q', 'se√±or', 'hecho', 'hablar', 'llevar', \n",
    "    'seguir', 'adem√°s', 'entonces', 'esperar', 'mundo', 'llegar', 'parecer', 'nunca', 'salir', 'persona', \n",
    "    'dejar', 'c√≥mo', 'a√±o', 'entonce', 'ma', 'pue', 'd√≠o', 'tal', 'volver', 'ah√≠', 'aqu√≠', 'meno', 'dos', \n",
    "    'nar', 'gracia', 'luego', '√∫nico', 'vez', 'dar √©l', 'dar', '√©l', 'ella', 'ello', 'mientras', 'caso', \n",
    "    'cada', 'dio', 'mejor', 'pueblo', 'gente', 'mas', 'menos', 'gracias', 'a√±os', 'm√°s', 'cosa', 'momento', \n",
    "    'asi', 'ano', 'mes', 'semana', 'semanas', 'aca', 'peor', 'meses', 'sera', 'mil', 'aqui', 'aun', 'sr', \n",
    "    'ahi', 'don', 'dr', 'sra', 'srita', 'habia', 'casi', 'unico', 'ala', 'usar', 'llego', 'porq', 'xk', \n",
    "    'xq', 'pq', 'pork', 'pues', 'Argentina', 'che', 'vos', 'boludo', 'mina', 'pibe', 'jajaja', 'jajajaja', 'jaja',\n",
    "    'haha', 'hahaha', 'hahahaha'\n",
    "]\n",
    "\n",
    "sample_frac=None#0.25\n",
    "\n",
    "n_volume=None#10000\n",
    "\n",
    "optimization = True\n",
    "\n",
    "min_topic = 4#2\n",
    "\n",
    "max_topic = 10#2\n",
    "\n",
    "k=None\n",
    "\n",
    "sep=','"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: üöÄ Usando optimizaci√≥n ULTRA autom√°ticamente para m√°ximo rendimiento\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Social_listening_data_process_and_modeling_LDA_ULTRA_OPTIMIZED' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Santi\\Documents\\atinna\\repos\\social-analysis\\lda\\NLP_optimized.py:1365\u001b[0m, in \u001b[0;36mSocial_listening_data_process_and_modeling_LDA_OPTIMIZED\u001b[1;34m(sep, path_data, path_output, path_output_model, column_names, filter_list, new_stop, min_topics, max_topics, step_size, k, n_cpu, n_cpu_lda, sample_frac, n_volume, n_data)\u001b[0m\n\u001b[0;32m   1354\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1355\u001b[0m \u001b[38;5;124;03mFunci√≥n principal optimizada - AHORA USA LA VERSI√ìN ULTRA POR DEFECTO.\u001b[39;00m\n\u001b[0;32m   1356\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1361\u001b[0m \u001b[38;5;124;03mSocial_listening_data_process_and_modeling_LDA()\u001b[39;00m\n\u001b[0;32m   1362\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1363\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müöÄ Usando optimizaci√≥n ULTRA autom√°ticamente para m√°ximo rendimiento\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSocial_listening_data_process_and_modeling_LDA_ULTRA_OPTIMIZED\u001b[49m(\n\u001b[0;32m   1366\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   1367\u001b[0m     path_data\u001b[38;5;241m=\u001b[39mpath_data,\n\u001b[0;32m   1368\u001b[0m     path_output\u001b[38;5;241m=\u001b[39mpath_output,\n\u001b[0;32m   1369\u001b[0m     path_output_model\u001b[38;5;241m=\u001b[39mpath_output_model,\n\u001b[0;32m   1370\u001b[0m     column_names\u001b[38;5;241m=\u001b[39mcolumn_names,\n\u001b[0;32m   1371\u001b[0m     filter_list\u001b[38;5;241m=\u001b[39mfilter_list,\n\u001b[0;32m   1372\u001b[0m     new_stop\u001b[38;5;241m=\u001b[39mnew_stop,\n\u001b[0;32m   1373\u001b[0m     min_topics\u001b[38;5;241m=\u001b[39mmin_topics,\n\u001b[0;32m   1374\u001b[0m     max_topics\u001b[38;5;241m=\u001b[39mmax_topics,\n\u001b[0;32m   1375\u001b[0m     step_size\u001b[38;5;241m=\u001b[39mstep_size,\n\u001b[0;32m   1376\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m   1377\u001b[0m     n_cpu\u001b[38;5;241m=\u001b[39mn_cpu,\n\u001b[0;32m   1378\u001b[0m     n_cpu_lda\u001b[38;5;241m=\u001b[39mn_cpu_lda,\n\u001b[0;32m   1379\u001b[0m     sample_frac\u001b[38;5;241m=\u001b[39msample_frac,\n\u001b[0;32m   1380\u001b[0m     n_volume\u001b[38;5;241m=\u001b[39mn_volume,\n\u001b[0;32m   1381\u001b[0m     n_data\u001b[38;5;241m=\u001b[39mn_data,\n\u001b[0;32m   1382\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Social_listening_data_process_and_modeling_LDA_ULTRA_OPTIMIZED' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "k_recommended = Social_listening_data_process_and_modeling_LDA_OPTIMIZED(\n",
    "        sep=sep,\n",
    "        path_data=file_path,\n",
    "        path_output= paths.paths['local']['output']['lda']['base'],\n",
    "        path_output_model= paths.paths['local']['output']['lda']['models'],\n",
    "        column_names=names,\n",
    "        filter_list=filter_list,\n",
    "        new_stop=new_stop,\n",
    "        sample_frac=sample_frac,\n",
    "        n_volume=n_volume,\n",
    "        min_topics=min_topic,\n",
    "        max_topics=max_topic,\n",
    "        step_size=1,\n",
    "        k=k,\n",
    "        n_cpu=6,\n",
    "        n_cpu_lda=8,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Procesamiento completado! K recomendado: {k_recommended}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MemoryManager' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:2\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MemoryManager' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipeline_result = {'success': False, 'error': 'Pipeline no ejecutado'} # Inicializar resultado\n",
    "memory_manager_instance = MemoryManager() # Instanciar para uso en esta celda\n",
    "\n",
    "print(\"üöÄ INICIANDO PIPELINE LDA OPTIMIZADO (CON run_lda_pipeline_wrapper)\")\n",
    "print(\"=\" * 60)\n",
    "start_datetime_pipeline = datetime.now()\n",
    "print(f\"üìÖ Inicio: {start_datetime_pipeline.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üíæ Memoria inicial (notebook): {memory_manager_instance.get_memory_usage():.2f} MB\")\n",
    "print()\n",
    "\n",
    "if not Path(file_path).exists():\n",
    "    logger.error(f\"El archivo de datos '{file_path}' no existe. No se puede ejecutar el pipeline.\")\n",
    "    pipeline_result = {'success': False, 'error': f'Archivo de datos no encontrado: {file_path}'}\n",
    "else:\n",
    "    try:\n",
    "        # Usar la funci√≥n wrapper del script nlp_lda_optimized.py\n",
    "        pipeline_result = run_lda_pipeline_wrapper(\n",
    "            path_data=str(file_path), # Asegurar que es string\n",
    "            path_output=str(local_output_lda_base), # Ruta base para todas las salidas del pipeline\n",
    "            sep=config_pipeline['sep'],\n",
    "            column_mapping=config_pipeline['column_mapping'],\n",
    "            filter_list=config_pipeline['filter_list'],\n",
    "            new_stop=config_pipeline['new_stop'],\n",
    "            min_topics=config_pipeline['min_topics'],\n",
    "            max_topics=config_pipeline['max_topics'],\n",
    "            step_size=config_pipeline['step_size'],\n",
    "            k=config_pipeline['k'],\n",
    "            n_cpu_lda=config_pipeline['n_cpu_lda'],\n",
    "            sample_frac=config_pipeline['sample_frac'],\n",
    "            n_volume=config_pipeline['n_volume'],\n",
    "            content_col_name=config_pipeline['content_col_name'],\n",
    "            domain_col_name=config_pipeline['domain_col_name'],\n",
    "            date_col_name=config_pipeline['date_col_name']\n",
    "        )\n",
    "        \n",
    "        if pipeline_result.get('success', False):\n",
    "            print(\"\\n‚úÖ PIPELINE COMPLETADO EXITOSAMENTE\")\n",
    "            print(\"=\" * 40)\n",
    "            print(f\"üéØ K recomendado: {pipeline_result.get('k_recommended', 'No determinado')}\")\n",
    "            print(f\"üìÅ Resultados guardados en la base: {pipeline_result.get('path_output_base')}\")\n",
    "            print(f\"üìÑ Datos procesados en: {pipeline_result.get('path_processed_data')}\")\n",
    "            print(f\"ü§ñ Modelos LDA en: {pipeline_result.get('path_lda_models')}\")\n",
    "            print(f\"üìà Resultados de coherencia LDA en: {pipeline_result.get('path_lda_results')}\")\n",
    "        else:\n",
    "            print(\"\\n‚ùå ERROR DURANTE LA EJECUCI√ìN DEL PIPELINE\")\n",
    "            print(\"=\" * 40)\n",
    "            print(f\"Tipo de Error: {pipeline_result.get('error_type', 'Desconocido')}\")\n",
    "            print(f\"Mensaje: {pipeline_result.get('error_message', 'No hay mensaje detallado.')}\")\n",
    "            logger.error(f\"Pipeline fall√≥: {pipeline_result.get('error_type', '')} - {pipeline_result.get('error_message', '')}\")\n",
    "            \n",
    "    except Exception as e_pipeline_cell:\n",
    "        print(f\"\\nüí• EXCEPCI√ìN NO CONTROLADA EN LA CELDA DEL PIPELINE: {e_pipeline_cell}\")\n",
    "        logger.error(f\"Error cr√≠tico en la celda de ejecuci√≥n del pipeline: {e_pipeline_cell}\", exc_info=True)\n",
    "        pipeline_result = {'success': False, 'error_type': type(e_pipeline_cell).__name__, 'error_message': str(e_pipeline_cell)}\n",
    "\n",
    "end_datetime_pipeline = datetime.now()\n",
    "print(f\"\\nüíæ Memoria final (notebook): {memory_manager_instance.get_memory_usage():.2f} MB\")\n",
    "print(f\"üìÖ Fin: {end_datetime_pipeline.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"‚è±Ô∏è Duraci√≥n total de la celda: {end_datetime_pipeline - start_datetime_pipeline}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MemoryManager' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:2\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MemoryManager' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipeline_result = {'success': False, 'error': 'Pipeline no ejecutado'} # Inicializar resultado\n",
    "memory_manager_instance = MemoryManager() # Instanciar para uso en esta celda\n",
    "\n",
    "print(\"üöÄ INICIANDO PIPELINE LDA OPTIMIZADO (CON run_lda_pipeline_wrapper)\")\n",
    "print(\"=\" * 60)\n",
    "start_datetime_pipeline = datetime.now()\n",
    "print(f\"üìÖ Inicio: {start_datetime_pipeline.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üíæ Memoria inicial (notebook): {memory_manager_instance.get_memory_usage():.2f} MB\")\n",
    "print()\n",
    "\n",
    "if not Path(file_path).exists():\n",
    "    logger.error(f\"El archivo de datos '{file_path}' no existe. No se puede ejecutar el pipeline.\")\n",
    "    pipeline_result = {'success': False, 'error': f'Archivo de datos no encontrado: {file_path}'}\n",
    "else:\n",
    "    try:\n",
    "        # Usar la funci√≥n wrapper del script nlp_lda_optimized.py\n",
    "        pipeline_result = run_lda_pipeline_wrapper(\n",
    "            path_data=str(file_path), # Asegurar que es string\n",
    "            path_output=str(local_output_lda_base), # Ruta base para todas las salidas del pipeline\n",
    "            sep=config_pipeline['sep'],\n",
    "            column_mapping=config_pipeline['column_mapping'],\n",
    "            filter_list=config_pipeline['filter_list'],\n",
    "            new_stop=config_pipeline['new_stop'],\n",
    "            min_topics=config_pipeline['min_topics'],\n",
    "            max_topics=config_pipeline['max_topics'],\n",
    "            step_size=config_pipeline['step_size'],\n",
    "            k=config_pipeline['k'],\n",
    "            n_cpu_lda=config_pipeline['n_cpu_lda'],\n",
    "            sample_frac=config_pipeline['sample_frac'],\n",
    "            n_volume=config_pipeline['n_volume'],\n",
    "            content_col_name=config_pipeline['content_col_name'],\n",
    "            domain_col_name=config_pipeline['domain_col_name'],\n",
    "            date_col_name=config_pipeline['date_col_name']\n",
    "        )\n",
    "        \n",
    "        if pipeline_result.get('success', False):\n",
    "            print(\"\\n‚úÖ PIPELINE COMPLETADO EXITOSAMENTE\")\n",
    "            print(\"=\" * 40)\n",
    "            print(f\"üéØ K recomendado: {pipeline_result.get('k_recommended', 'No determinado')}\")\n",
    "            print(f\"üìÅ Resultados guardados en la base: {pipeline_result.get('path_output_base')}\")\n",
    "            print(f\"üìÑ Datos procesados en: {pipeline_result.get('path_processed_data')}\")\n",
    "            print(f\"ü§ñ Modelos LDA en: {pipeline_result.get('path_lda_models')}\")\n",
    "            print(f\"üìà Resultados de coherencia LDA en: {pipeline_result.get('path_lda_results')}\")\n",
    "        else:\n",
    "            print(\"\\n‚ùå ERROR DURANTE LA EJECUCI√ìN DEL PIPELINE\")\n",
    "            print(\"=\" * 40)\n",
    "            print(f\"Tipo de Error: {pipeline_result.get('error_type', 'Desconocido')}\")\n",
    "            print(f\"Mensaje: {pipeline_result.get('error_message', 'No hay mensaje detallado.')}\")\n",
    "            logger.error(f\"Pipeline fall√≥: {pipeline_result.get('error_type', '')} - {pipeline_result.get('error_message', '')}\")\n",
    "            \n",
    "    except Exception as e_pipeline_cell:\n",
    "        print(f\"\\nüí• EXCEPCI√ìN NO CONTROLADA EN LA CELDA DEL PIPELINE: {e_pipeline_cell}\")\n",
    "        logger.error(f\"Error cr√≠tico en la celda de ejecuci√≥n del pipeline: {e_pipeline_cell}\", exc_info=True)\n",
    "        pipeline_result = {'success': False, 'error_type': type(e_pipeline_cell).__name__, 'error_message': str(e_pipeline_cell)}\n",
    "\n",
    "end_datetime_pipeline = datetime.now()\n",
    "print(f\"\\nüíæ Memoria final (notebook): {memory_manager_instance.get_memory_usage():.2f} MB\")\n",
    "print(f\"üìÖ Fin: {end_datetime_pipeline.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"‚è±Ô∏è Duraci√≥n total de la celda: {end_datetime_pipeline - start_datetime_pipeline}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MemoryManager' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:2\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MemoryManager' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipeline_result = {'success': False, 'error': 'Pipeline no ejecutado'} # Inicializar resultado\n",
    "memory_manager_instance = MemoryManager() # Instanciar para uso en esta celda\n",
    "\n",
    "print(\"üöÄ INICIANDO PIPELINE LDA OPTIMIZADO (CON run_lda_pipeline_wrapper)\")\n",
    "print(\"=\" * 60)\n",
    "start_datetime_pipeline = datetime.now()\n",
    "print(f\"üìÖ Inicio: {start_datetime_pipeline.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üíæ Memoria inicial (notebook): {memory_manager_instance.get_memory_usage():.2f} MB\")\n",
    "print()\n",
    "\n",
    "if not Path(file_path).exists():\n",
    "    logger.error(f\"El archivo de datos '{file_path}' no existe. No se puede ejecutar el pipeline.\")\n",
    "    pipeline_result = {'success': False, 'error': f'Archivo de datos no encontrado: {file_path}'}\n",
    "else:\n",
    "    try:\n",
    "        # Usar la funci√≥n wrapper del script nlp_lda_optimized.py\n",
    "        pipeline_result = run_lda_pipeline_wrapper(\n",
    "            path_data=str(file_path), # Asegurar que es string\n",
    "            path_output=str(local_output_lda_base), # Ruta base para todas las salidas del pipeline\n",
    "            sep=config_pipeline['sep'],\n",
    "            column_mapping=config_pipeline['column_mapping'],\n",
    "            filter_list=config_pipeline['filter_list'],\n",
    "            new_stop=config_pipeline['new_stop'],\n",
    "            min_topics=config_pipeline['min_topics'],\n",
    "            max_topics=config_pipeline['max_topics'],\n",
    "            step_size=config_pipeline['step_size'],\n",
    "            k=config_pipeline['k'],\n",
    "            n_cpu_lda=config_pipeline['n_cpu_lda'],\n",
    "            sample_frac=config_pipeline['sample_frac'],\n",
    "            n_volume=config_pipeline['n_volume'],\n",
    "            content_col_name=config_pipeline['content_col_name'],\n",
    "            domain_col_name=config_pipeline['domain_col_name'],\n",
    "            date_col_name=config_pipeline['date_col_name']\n",
    "        )\n",
    "        \n",
    "        if pipeline_result.get('success', False):\n",
    "            print(\"\\n‚úÖ PIPELINE COMPLETADO EXITOSAMENTE\")\n",
    "            print(\"=\" * 40)\n",
    "            print(f\"üéØ K recomendado: {pipeline_result.get('k_recommended', 'No determinado')}\")\n",
    "            print(f\"üìÅ Resultados guardados en la base: {pipeline_result.get('path_output_base')}\")\n",
    "            print(f\"üìÑ Datos procesados en: {pipeline_result.get('path_processed_data')}\")\n",
    "            print(f\"ü§ñ Modelos LDA en: {pipeline_result.get('path_lda_models')}\")\n",
    "            print(f\"üìà Resultados de coherencia LDA en: {pipeline_result.get('path_lda_results')}\")\n",
    "        else:\n",
    "            print(\"\\n‚ùå ERROR DURANTE LA EJECUCI√ìN DEL PIPELINE\")\n",
    "            print(\"=\" * 40)\n",
    "            print(f\"Tipo de Error: {pipeline_result.get('error_type', 'Desconocido')}\")\n",
    "            print(f\"Mensaje: {pipeline_result.get('error_message', 'No hay mensaje detallado.')}\")\n",
    "            logger.error(f\"Pipeline fall√≥: {pipeline_result.get('error_type', '')} - {pipeline_result.get('error_message', '')}\")\n",
    "            \n",
    "    except Exception as e_pipeline_cell:\n",
    "        print(f\"\\nüí• EXCEPCI√ìN NO CONTROLADA EN LA CELDA DEL PIPELINE: {e_pipeline_cell}\")\n",
    "        logger.error(f\"Error cr√≠tico en la celda de ejecuci√≥n del pipeline: {e_pipeline_cell}\", exc_info=True)\n",
    "        pipeline_result = {'success': False, 'error_type': type(e_pipeline_cell).__name__, 'error_message': str(e_pipeline_cell)}\n",
    "\n",
    "end_datetime_pipeline = datetime.now()\n",
    "print(f\"\\nüíæ Memoria final (notebook): {memory_manager_instance.get_memory_usage():.2f} MB\")\n",
    "print(f\"üìÖ Fin: {end_datetime_pipeline.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"‚è±Ô∏è Duraci√≥n total de la celda: {end_datetime_pipeline - start_datetime_pipeline}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MemoryManager' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:2\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MemoryManager' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipeline_result = {'success': False, 'error': 'Pipeline no ejecutado'} # Inicializar resultado\n",
    "memory_manager_instance = MemoryManager() # Instanciar para uso en esta celda\n",
    "\n",
    "print(\"üöÄ INICIANDO PIPELINE LDA OPTIMIZADO (CON run_lda_pipeline_wrapper)\")\n",
    "print(\"=\" * 60)\n",
    "start_datetime_pipeline = datetime.now()\n",
    "print(f\"üìÖ Inicio: {start_datetime_pipeline.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üíæ Memoria inicial (notebook): {memory_manager_instance.get_memory_usage():.2f} MB\")\n",
    "print()\n",
    "\n",
    "if not Path(file_path).exists():\n",
    "    logger.error(f\"El archivo de datos '{file_path}' no existe. No se puede ejecutar el pipeline.\")\n",
    "    pipeline_result = {'success': False, 'error': f'Archivo de datos no encontrado: {file_path}'}\n",
    "else:\n",
    "    try:\n",
    "        # Usar la funci√≥n wrapper del script nlp_lda_optimized.py\n",
    "        pipeline_result = run_lda_pipeline_wrapper(\n",
    "            path_data=str(file_path), # Asegurar que es string\n",
    "            path_output=str(local_output_lda_base), # Ruta base para todas las salidas del pipeline\n",
    "            sep=config_pipeline['sep'],\n",
    "            column_mapping=config_pipeline['column_mapping'],\n",
    "            filter_list=config_pipeline['filter_list'],\n",
    "            new_stop=config_pipeline['new_stop'],\n",
    "            min_topics=config_pipeline['min_topics'],\n",
    "            max_topics=config_pipeline['max_topics'],\n",
    "            step_size=config_pipeline['step_size'],\n",
    "            k=config_pipeline['k'],\n",
    "            n_cpu_lda=config_pipeline['n_cpu_lda'],\n",
    "            sample_frac=config_pipeline['sample_frac'],\n",
    "            n_volume=config_pipeline['n_volume'],\n",
    "            content_col_name=config_pipeline['content_col_name'],\n",
    "            domain_col_name=config_pipeline['domain_col_name'],\n",
    "            date_col_name=config_pipeline['date_col_name']\n",
    "        )\n",
    "        \n",
    "        if pipeline_result.get('success', False):\n",
    "            print(\"\\n‚úÖ PIPELINE COMPLETADO EXITOSAMENTE\")\n",
    "            print(\"=\" * 40)\n",
    "            print(f\"üéØ K recomendado: {pipeline_result.get('k_recommended', 'No determinado')}\")\n",
    "            print(f\"üìÅ Resultados guardados en la base: {pipeline_result.get('path_output_base')}\")\n",
    "            print(f\"üìÑ Datos procesados en: {pipeline_result.get('path_processed_data')}\")\n",
    "            print(f\"ü§ñ Modelos LDA en: {pipeline_result.get('path_lda_models')}\")\n",
    "            print(f\"üìà Resultados de coherencia LDA en: {pipeline_result.get('path_lda_results')}\")\n",
    "        else:\n",
    "            print(\"\\n‚ùå ERROR DURANTE LA EJECUCI√ìN DEL PIPELINE\")\n",
    "            print(\"=\" * 40)\n",
    "            print(f\"Tipo de Error: {pipeline_result.get('error_type', 'Desconocido')}\")\n",
    "            print(f\"Mensaje: {pipeline_result.get('error_message', 'No hay mensaje detallado.')}\")\n",
    "            logger.error(f\"Pipeline fall√≥: {pipeline_result.get('error_type', '')} - {pipeline_result.get('error_message', '')}\")\n",
    "            \n",
    "    except Exception as e_pipeline_cell:\n",
    "        print(f\"\\nüí• EXCEPCI√ìN NO CONTROLADA EN LA CELDA DEL PIPELINE: {e_pipeline_cell}\")\n",
    "        logger.error(f\"Error cr√≠tico en la celda de ejecuci√≥n del pipeline: {e_pipeline_cell}\", exc_info=True)\n",
    "        pipeline_result = {'success': False, 'error_type': type(e_pipeline_cell).__name__, 'error_message': str(e_pipeline_cell)}\n",
    "\n",
    "end_datetime_pipeline = datetime.now()\n",
    "print(f\"\\nüíæ Memoria final (notebook): {memory_manager_instance.get_memory_usage():.2f} MB\")\n",
    "print(f\"üìÖ Fin: {end_datetime_pipeline.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"‚è±Ô∏è Duraci√≥n total de la celda: {end_datetime_pipeline - start_datetime_pipeline}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MemoryManager' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:2\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MemoryManager' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipeline_result = {'success': False, 'error': 'Pipeline no ejecutado'} # Inicializar resultado\n",
    "memory_manager_instance = MemoryManager() # Instanciar para uso en esta celda\n",
    "\n",
    "print(\"üöÄ INICIANDO PIPELINE LDA OPTIMIZADO (CON run_lda_pipeline_wrapper)\")\n",
    "print(\"=\" * 60)\n",
    "start_datetime_pipeline = datetime.now()\n",
    "print(f\"üìÖ Inicio: {start_datetime_pipeline.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üíæ Memoria inicial (notebook): {memory_manager_instance.get_memory_usage():.2f} MB\")\n",
    "print()\n",
    "\n",
    "if not Path(file_path).exists():\n",
    "    logger.error(f\"El archivo de datos '{file_path}' no existe. No se puede ejecutar el pipeline.\")\n",
    "    pipeline_result = {'success': False, 'error': f'Archivo de datos no encontrado: {file_path}'}\n",
    "else:\n",
    "    try:\n",
    "        # Usar la funci√≥n wrapper del script nlp_lda_optimized.py\n",
    "        pipeline_result = run_lda_pipeline_wrapper(\n",
    "            path_data=str(file_path), # Asegurar que es string\n",
    "            path_output=str(local_output_lda_base), # Ruta base para todas las salidas del pipeline\n",
    "            sep=config_pipeline['sep'],\n",
    "            column_mapping=config_pipeline['column_mapping'],\n",
    "            filter_list=config_pipeline['filter_list'],\n",
    "            new_stop=config_pipeline['new_stop'],\n",
    "            min_topics=config_pipeline['min_topics'],\n",
    "            max_topics=config_pipeline['max_topics'],\n",
    "            step_size=config_pipeline['step_size'],\n",
    "            k=config_pipeline['k'],\n",
    "            n_cpu_lda=config_pipeline['n_cpu_lda'],\n",
    "            sample_frac=config_pipeline['sample_frac'],\n",
    "            n_volume=config_pipeline['n_volume'],\n",
    "            content_col_name=config_pipeline['content_col_name'],\n",
    "            domain_col_name=config_pipeline['domain_col_name'],\n",
    "            date_col_name=config_pipeline['date_col_name']\n",
    "        )\n",
    "        \n",
    "        if pipeline_result.get('success', False):\n",
    "            print(\"\\n‚úÖ PIPELINE COMPLETADO EXITOSAMENTE\")\n",
    "            print(\"=\" * 40)\n",
    "            print(f\"üéØ K recomendado: {pipeline_result.get('k_recommended', 'No determinado')}\")\n",
    "            print(f\"üìÅ Resultados guardados en la base: {pipeline_result.get('path_output_base')}\")\n",
    "            print(f\"üìÑ Datos procesados en: {pipeline_result.get('path_processed_data')}\")\n",
    "            print(f\"ü§ñ Modelos LDA en: {pipeline_result.get('path_lda_models')}\")\n",
    "            print(f\"üìà Resultados de coherencia LDA en: {pipeline_result.get('path_lda_results')}\")\n",
    "        else:\n",
    "            print(\"\\n‚ùå ERROR DURANTE LA EJECUCI√ìN DEL PIPELINE\")\n",
    "            print(\"=\" * 40)\n",
    "            print(f\"Tipo de Error: {pipeline_result.get('error_type', 'Desconocido')}\")\n",
    "            print(f\"Mensaje: {pipeline_result.get('error_message', 'No hay mensaje detallado.')}\")\n",
    "            logger.error(f\"Pipeline fall√≥: {pipeline_result.get('error_type', '')} - {pipeline_result.get('error_message', '')}\")\n",
    "            \n",
    "    except Exception as e_pipeline_cell:\n",
    "        print(f\"\\nüí• EXCEPCI√ìN NO CONTROLADA EN LA CELDA DEL PIPELINE: {e_pipeline_cell}\")\n",
    "        logger.error(f\"Error cr√≠tico en la celda de ejecuci√≥n del pipeline: {e_pipeline_cell}\", exc_info=True)\n",
    "        pipeline_result = {'success': False, 'error_type': type(e_pipeline_cell).__name__, 'error_message': str(e_pipeline_cell)}\n",
    "\n",
    "end_datetime_pipeline = datetime.now()\n",
    "print(f\"\\nüíæ Memoria final (notebook): {memory_manager_instance.get_memory_usage():.2f} MB\")\n",
    "print(f\"üìÖ Fin: {end_datetime_pipeline.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"‚è±Ô∏è Duraci√≥n total de la celda: {end_datetime_pipeline - start_datetime_pipeline}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MemoryManager' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:2\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MemoryManager' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipeline_result = {'success': False, 'error': 'Pipeline no ejecutado'} # Inicializar resultado\n",
    "memory_manager_instance = MemoryManager() # Instanciar para uso en esta celda\n",
    "\n",
    "print(\"üöÄ INICIANDO PIPELINE LDA OPTIMIZADO (CON run_lda_pipeline_wrapper)\")\n",
    "print(\"=\" * 60)\n",
    "start_datetime_pipeline = datetime.now()\n",
    "print(f\"üìÖ Inicio: {start_datetime_pipeline.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üíæ Memoria inicial (notebook): {memory_manager_instance.get_memory_usage():.2f} MB\")\n",
    "print()\n",
    "\n",
    "if not Path(file_path).exists():\n",
    "    logger.error(f\"El archivo de datos '{file_path}' no existe. No se puede ejecutar el pipeline.\")\n",
    "    pipeline_result = {'success': False, 'error': f'Archivo de datos no encontrado: {file_path}'}\n",
    "else:\n",
    "    try:\n",
    "        # Usar la funci√≥n wrapper del script nlp_lda_optimized.py\n",
    "        pipeline_result = run_lda_pipeline_wrapper(\n",
    "            path_data=str(file_path), # Asegurar que es string\n",
    "            path_output=str(local_output_lda_base), # Ruta base para todas las salidas del pipeline\n",
    "            sep=config_pipeline['sep'],\n",
    "            column_mapping=config_pipeline['column_mapping'],\n",
    "            filter_list=config_pipeline['filter_list'],\n",
    "            new_stop=config_pipeline['new_stop'],\n",
    "            min_topics=config_pipeline['min_topics'],\n",
    "            max_topics=config_pipeline['max_topics'],\n",
    "            step_size=config_pipeline['step_size'],\n",
    "            k=config_pipeline['k'],\n",
    "            n_cpu_lda=config_pipeline['n_cpu_lda'],\n",
    "            sample_frac=config_pipeline['sample_frac'],\n",
    "            n_volume=config_pipeline['n_volume'],\n",
    "            content_col_name=config_pipeline['content_col_name'],\n",
    "            domain_col_name=config_pipeline['domain_col_name'],\n",
    "            date_col_name=config_pipeline['date_col_name']\n",
    "        )\n",
    "        \n",
    "        if pipeline_result.get('success', False):\n",
    "            print(\"\\n‚úÖ PIPELINE COMPLETADO EXITOSAMENTE\")\n",
    "            print(\"=\" * 40)\n",
    "            print(f\"üéØ K recomendado: {pipeline_result.get('k_recommended', 'No determinado')}\")\n",
    "            print(f\"üìÅ Resultados guardados en la base: {pipeline_result.get('path_output_base')}\")\n",
    "            print(f\"üìÑ Datos procesados en: {pipeline_result.get('path_processed_data')}\")\n",
    "            print(f\"ü§ñ Modelos LDA en: {pipeline_result.get('path_lda_models')}\")\n",
    "            print(f\"üìà Resultados de coherencia LDA en: {pipeline_result.get('path_lda_results')}\")\n",
    "        else:\n",
    "            print(\"\\n‚ùå ERROR DURANTE LA EJECUCI√ìN DEL PIPELINE\")\n",
    "            print(\"=\" * 40)\n",
    "            print(f\"Tipo de Error: {pipeline_result.get('error_type', 'Desconocido')}\")\n",
    "            print(f\"Mensaje: {pipeline_result.get('error_message', 'No hay mensaje detallado.')}\")\n",
    "            logger.error(f\"Pipeline fall√≥: {pipeline_result.get('error_type', '')} - {pipeline_result.get('error_message', '')}\")\n",
    "            \n",
    "    except Exception as e_pipeline_cell:\n",
    "        print(f\"\\nüí• EXCEPCI√ìN NO CONTROLADA EN LA CELDA DEL PIPELINE: {e_pipeline_cell}\")\n",
    "        logger.error(f\"Error cr√≠tico en la celda de ejecuci√≥n del pipeline: {e_pipeline_cell}\", exc_info=True)\n",
    "        pipeline_result = {'success': False, 'error_type': type(e_pipeline_cell).__name__, 'error_message': str(e_pipeline_cell)}\n",
    "\n",
    "end_datetime_pipeline = datetime.now()\n",
    "print(f\"\\nüíæ Memoria final (notebook): {memory_manager_instance.get_memory_usage():.2f} MB\")\n",
    "print(f\"üìÖ Fin: {end_datetime_pipeline.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"‚è±Ô∏è Duraci√≥n total de la celda: {end_datetime_pipeline - start_datetime_pipeline}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MemoryManager' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:2\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MemoryManager' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipeline_result = {'success': False, 'error': 'Pipeline no ejecutado'} # Inicializar resultado\n",
    "memory_manager_instance = MemoryManager() # Instanciar para uso en esta celda\n",
    "\n",
    "print(\"üöÄ INICIANDO PIPELINE LDA OPTIMIZADO (CON run_lda_pipeline_wrapper)\")\n",
    "print(\"=\" * 60)\n",
    "start_datetime_pipeline = datetime.now()\n",
    "print(f\"üìÖ Inicio: {start_datetime_pipeline.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üíæ Memoria inicial (notebook): {memory_manager_instance.get_memory_usage():.2f} MB\")\n",
    "print()\n",
    "\n",
    "if not Path(file_path).exists():\n",
    "    logger.error(f\"El archivo de datos '{file_path}' no existe. No se puede ejecutar el pipeline.\")\n",
    "    pipeline_result = {'success': False, 'error': f'Archivo de datos no encontrado: {file_path}'}\n",
    "else:\n",
    "    try:\n",
    "        # Usar la funci√≥n wrapper del script nlp_lda_optimized.py\n",
    "        pipeline_result = run_lda_pipeline_wrapper(\n",
    "            path_data=str(file_path), # Asegurar que es string\n",
    "            path_output=str(local_output_lda_base), # Ruta base para todas las salidas del pipeline\n",
    "            sep=config_pipeline['sep'],\n",
    "            column_mapping=config_pipeline['column_mapping'],\n",
    "            filter_list=config_pipeline['filter_list'],\n",
    "            new_stop=config_pipeline['new_stop'],\n",
    "            min_topics=config_pipeline['min_topics'],\n",
    "            max_topics=config_pipeline['max_topics'],\n",
    "            step_size=config_pipeline['step_size'],\n",
    "            k=config_pipeline['k'],\n",
    "            n_cpu_lda=config_pipeline['n_cpu_lda'],\n",
    "            sample_frac=config_pipeline['sample_frac'],\n",
    "            n_volume=config_pipeline['n_volume'],\n",
    "            content_col_name=config_pipeline['content_col_name'],\n",
    "            domain_col_name=config_pipeline['domain_col_name'],\n",
    "            date_col_name=config_pipeline['date_col_name']\n",
    "        )\n",
    "        \n",
    "        if pipeline_result.get('success', False):\n",
    "            print(\"\\n‚úÖ PIPELINE COMPLETADO EXITOSAMENTE\")\n",
    "            print(\"=\" * 40)\n",
    "            print(f\"üéØ K recomendado: {pipeline_result.get('k_recommended', 'No determinado')}\")\n",
    "            print(f\"üìÅ Resultados guardados en la base: {pipeline_result.get('path_output_base')}\")\n",
    "            print(f\"üìÑ Datos procesados en: {pipeline_result.get('path_processed_data')}\")\n",
    "            print(f\"ü§ñ Modelos LDA en: {pipeline_result.get('path_lda_models')}\")\n",
    "            print(f\"üìà Resultados de coherencia LDA en: {pipeline_result.get('path_lda_results')}\")\n",
    "        else:\n",
    "            print(\"\\n‚ùå ERROR DURANTE LA EJECUCI√ìN DEL PIPELINE\")\n",
    "            print(\"=\" * 40)\n",
    "            print(f\"Tipo de Error: {pipeline_result.get('error_type', 'Desconocido')}\")\n",
    "            print(f\"Mensaje: {pipeline_result.get('error_message', 'No hay mensaje detallado.')}\")\n",
    "            logger.error(f\"Pipeline fall√≥: {pipeline_result.get('error_type', '')} - {pipeline_result.get('error_message', '')}\")\n",
    "            \n",
    "    except Exception as e_pipeline_cell:\n",
    "        print(f\"\\nüí• EXCEPCI√ìN NO CONTROLADA EN LA CELDA DEL PIPELINE: {e_pipeline_cell}\")\n",
    "        logger.error(f\"Error cr√≠tico en la celda de ejecuci√≥n del pipeline: {e_pipeline_cell}\", exc_info=True)\n",
    "        pipeline_result = {'success': False, 'error_type': type(e_pipeline_cell).__name__, 'error_message': str(e_pipeline_cell)}\n",
    "\n",
    "end_datetime_pipeline = datetime.now()\n",
    "print(f\"\\nüíæ Memoria final (notebook): {memory_manager_instance.get_memory_usage():.2f} MB\")\n",
    "print(f\"üìÖ Fin: {end_datetime_pipeline.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"‚è±Ô∏è Duraci√≥n total de la celda: {end_datetime_pipeline - start_datetime_pipeline}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "Contains information about the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Santi/Documents/atinna/repos/escuchas\\\\Azul\\\\salud\\\\2025-04-01_2025-04-30\\\\v1.0\\\\lda\\\\metadata.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m path_metadata \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(paths\u001b[38;5;241m.\u001b[39mpaths[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlda\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[43mjson_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m metadata\n",
      "File \u001b[1;32mc:\\Users\\Santi\\Documents\\atinna\\repos\\social-analysis\\lda\\NLP_optimized.py:836\u001b[0m, in \u001b[0;36mjson_read\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mjson_read\u001b[39m(filename: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    835\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read Json file.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 836\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8-sig\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f_in:\n\u001b[0;32m    837\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mload(f_in)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Santi/Documents/atinna/repos/escuchas\\\\Azul\\\\salud\\\\2025-04-01_2025-04-30\\\\v1.0\\\\lda\\\\metadata.json'"
     ]
    }
   ],
   "source": [
    "path_metadata = os.path.join(paths.paths['local']['output']['lda']['base'],\"metadata.json\")\n",
    "metadata = json_read(path_metadata)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashtags frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hash_global_polars.csv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in os.listdir(paths.paths['local']['output']['lda']['base']) if 'Hash'in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash= [local_reading(path=paths.paths['local']['output']['lda']['base']+i) for i in os.listdir(paths.paths['local']['output']['lda']['base']) if 'Hash'in i]\n",
    "hash[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most repeated posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repe= [local_reading(path=paths['local']['output']['base']+i) for i in os.listdir(paths['local']['output']['base']) if 'Repea'in i]\n",
    "# df_repe = Repe[0].head(15).set_index('content')\n",
    "# df_repe [df_repe['count']>1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Netw= [local_reading(path=paths.paths['local']['output']['lda']['base']+i) for i in os.listdir(paths.paths['local']['output']['lda']['base']) if 'net'in i]\n",
    "Netw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Carpeta 'espectro_politico/2025-04-01_2025-04-30/v3.0/output/lda' encontrada o creada en SharePoint con ID: 01R4PBSE4OG4XZ5T4TRVFJNG5STBW2AFHK\n",
      "üìÇ Carpeta 'espectro_politico/2025-04-01_2025-04-30/v3.0/output/lda/figures' encontrada o creada en SharePoint con ID: 01R4PBSEZI4PHVD6FUQFCZBVEZOGJEUSP3\n",
      "‚ùå Error uploading file 'Hash_global_polars.csv': The specified item name already exists.\n",
      "‚ùå Error al subir el archivo 'Hash_global_polars.csv'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'success': False,\n",
       " 'files_uploaded': 0,\n",
       " 'files_failed': 1,\n",
       " 'folders_created': 0,\n",
       " 'errors': [\"Error al subir el archivo 'Hash_global_polars.csv'.\"]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mg.upload_folder(headers, site_id, dev_folder_id, paths.paths['local']['output']['lda']['base'], paths.paths['cloud']['output']['lda']['base'], separator=\"/\", conflict_behavior=\"fail\", skip_on_error=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "social-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
